{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copyfile\n",
    "import os\n",
    "from keras.preprocessing.image import load_img ,img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rescale\n",
    "import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import os \n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from google.colab import drive\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive/')\n",
    "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/data.zip\", 'r')\n",
    "zip_ref.extractall(\"/tmp\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(128 * 32 * 32)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((32, 32, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = os.listdir('data')\n",
    "data_train_gan = np.array([resize(imread(os.path.join('data',file_name)), (64, 64)) for file_name in list_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train_gan\n",
    "iterations = 10000\n",
    "batch_size = 64\n",
    "save_dir = '.'\n",
    "start = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm_notebook(range(iterations)):\n",
    "  random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))\n",
    "  generated_images = generator.predict(random_latent_vectors)\n",
    "  stop = start + batch_size\n",
    "  real_images = x_train[start: stop]\n",
    "  combined_images = np.concatenate([generated_images, real_images])\n",
    "  labels = np.concatenate([np.ones((batch_size,1)), \n",
    "                                    np.zeros((batch_size, 1))])\n",
    "  labels += 0.05 * np.random.random(labels.shape)\n",
    "  \n",
    "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "  \n",
    "  random_latent_vectors = np.random.normal(size=(batch_size, \n",
    "                                                 latent_dim))\n",
    "  misleading_targets = np.zeros((batch_size, 1))\n",
    "  a_loss = gan.train_on_batch(random_latent_vectors, \n",
    "                              misleading_targets)\n",
    "  start += batch_size\n",
    "  \n",
    "  if start > len(x_train) - batch_size:\n",
    "    start = 0\n",
    " \n",
    "  if step % 10 == 0:\n",
    "    print('discriminator loss:', d_loss)\n",
    "    print('advesarial loss:', a_loss)\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    fig.set_size_inches(2,2)\n",
    "    count = 0\n",
    "    for i in range(2):\n",
    "      for j in range(2):\n",
    "        axes[i, j].imshow(resize(generated_images[count], (64,64)))\n",
    "        axes[i, j].axis('off')\n",
    "        count += 1\n",
    "    plt.show()\n",
    "    \n",
    "  if step % 100 == 0:\n",
    "    print('discriminator loss:', d_loss)\n",
    "    print('advesarial loss:', a_loss)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
